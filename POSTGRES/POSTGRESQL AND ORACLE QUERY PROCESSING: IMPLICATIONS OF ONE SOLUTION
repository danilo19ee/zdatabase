#########################################################################
# POSTGRESQL AND ORACLE QUERY PROCESSING: IMPLICATIONS OF ONE SOLUTION  #
#########################################################################

SQL query processing in both Oracle and Postgres has a lot in common. One way or another, it is necessary to perform parsing, 
check the semantics (which requires meta information, and it does not matter whether it is called a "data dictionary" or a "system catalog"), 
perform some transformations, build an optimal execution plan (in both systems, based on the cost, and therefore requiring pre-collected statistics).

But there is one single significant difference that fundamentally changes the whole approach to processing. Of course, 
we are talking about the fact that Oracle uses the global parsed query cache, and Postgres stores queries locally.

In the article we will try to trace how, due to the difference in one architectural solution, completely different ideology of work in queries in two DBMS logically follows.

The examples provided (which were run on Oracle 11.2 XE and PostgreSQL 9.4) show the query execution time. We are only interested in relative values: 
how many times the execution time changed after making certain changes to the query. At the same time, the absolute figures can differ by orders of magnitude, 
depending on the equipment, load and settings. In order not to give reason for meaningless conclusions based on them, 
all the absolute values in the article are scaled so that one of the requests is 10 seconds in both systems.

------------
-- ORACLE --
------------

Oracle uses an instance-wide library cache (library cache). The plan of any executed query is guaranteed to be in the cache: 
either the query is executed with a ready-made plan from the cache, or a new plan is built and stored in the cache - and this happens automatically.

In a simplified way, the general scheme of query execution can be represented as follows:

1 - Parse the query (whether the SQL command is written correctly).
2 - Semantic analysis (whether the specified objects exist and whether there is access to them).
3 - If the ready plan is in the cache, then use it; otherwise - further.
4 - Transformation (rewriting a query according to heuristic rules).
5 - Optimization (selection of an execution plan with the lowest cost).
6 - Putting the selected plan into the cache.

The same request repeated twice in a row will be processed differently. The first time, the so-called hard parse will take place - from the first to the last point. 
The second time, only a partial parsing (soft parse) will be performed - syntactic and semantic analysis - after which a ready-made plan will be found and used in the cache, 
which is much more efficient.

The presence of the global cache encourages us to minimize the number of entries in it. 
One reason is that a large stream of "one-off" requests can force the plans out of the cache, while the requests themselves will never be repeated. But most importantly, 
concurrent processes access the shared cache, therefore, it must be protected by locks and writing to it can become a bottleneck.

Indeed, a process doing a lot of parsing becomes an instance-wide problem. Consider this situation with the following example: Here we create a table, 
insert hundreds of thousands of rows into it (the "from dual connect by rowid <= N" construct is an idiom for generating a selection of N rows) and collect statistics. 
Let's execute the following PL / SQL code that updates the table line by line in a loop using dynamically generated update queries (this example may look contrived, 
but in practice it is not so): If you trace, then you can find out:

create table t(
id number primary key,
n number not null);
insert into t(id, n) select level, 1 from dual connect by rownum <= 100000; 
exec dbms_stats.gather_table_stats(user,'T');
alter session set statistics_level=all;

begin
for i in (select id from t) loop
execute immediate 'update t set n = n + 1 where id = '||i.id;
end loop;
commit;
end;
/

OVERALL TOTALS FOR ALL RECURSIVE STATEMENTS

call    count  cpu      elapsed    disk       query      current    rows
------- ------ -------- ---------- ---------- ---------- ---------- ----------
Parse   100003 92.63    95.40       0         2837        0         0
Execute 100003 13.57    14.29       0         200002      102225    100000
Fetch   1002   0.87     0.75        0         10173       0         100000
------- ------ -------- ---------- ---------- ---------- ---------- ----------
total   201008 107.08   110.46      0         213012      102225    200000

Misses in library cache during parse: 100001

Shown here is information for all SQL queries initiated from a block of code. 
The elapsed column shows the total elapsed time (which is the sum of cpu and various expectations), and the parse, execute, 
fetch lines correspond to the stages of parsing, executing and getting the results of the query. 
As you can see, most of the time (95 seconds out of 110, the elapsed column) was spent on parsing a hundred thousand (count column) queries of the same 
type and placing their one-time plans in the cache. If you run several similar processes at the same time, 
you will start to see expectations like "latch: shared pool" and "latch: row cache objects" (names vary from version to version), 
indicating competition for access to the library cache.

To prevent this from happening, it is customary in Oracle to use bind variables. For example, like this:

begin
for i in (select id from t) loop
execute immediate 'update t set n = n + 1 where id = :A' using i.id;
end loop;
commit;
end;
/

Or, more simply, without dynamic SQL, since PL / SQL automatically converts its variables to database bind variables: Here is what the trace will show in this case: 
The parsing time has been reduced to a minimum - all update queries now look the same for the DBMS. "Equality", that is, in fact, the key for the cache, 
is determined by two values:

begin
for i in (select id from t) loop
update t set n = n + 1 where id = i.id;
end loop;
commit;
end;
/

OVERALL TOTALS FOR ALL RECURSIVE STATEMENTS

call    count  cpu      elapsed    disk       query      current    rows
------- ------ -------- ---------- ---------- ---------- ---------- ----------
Parse   3       0.02    0.03        0         297         0         0
Execute 100002  9.08    9.28        0         201694      102315    100000
Fetch   1001    0.77    0.68        0         10173       0         100000
------- ------ -------- ---------- ---------- ---------- ---------- ----------
total   101006  9.87    10.00       0         212164      102315    200000

Thus, the update query is parsed only once (the 3 in the count column corresponds to the parsing of the PL / SQL block, the select query in the for clause, 
and the update query in the loop body). His plan is placed in the cache and then everything works relatively quickly.
(Why "relatively"? Because the correct way is to perform the update with one command "update t set n = n + 1", which runs even an order of magnitude faster.)
However, the "general" query plan, built without taking into account the values ​​of the variables, will only be adequate for evenly distributed data.
Let's change the table: add and index the flag field equal to "Y" for 0.1% of rows and "N" for the remaining 99.9%. 
For the optimizer to take into account the unevenness of the data in the flag field, it is required to collect a histogram for this field. For example, like this:

alter table t add (flag char(1) check (flag in ('Y','N')));
update t set flag = case when mod(id,1000)=0 then 'Y' else 'N' end;
create index t_flag on t(flag);
exec dbms_stats.gather_table_stats(user,'T',method_opt=>'for columns flag size 2');

Interestingly, the explain plan command (the result of which is available using the dbms_xplan.display function) 
will still show the plan built on the assumption of uniformity, as if the optimizer expects to receive half of the table: 
This only means that by and large use the explain plan command in Orakla it is impossible. It does not take into account either the values of variables or their types, 
and the plan generated by it does not get into the cache and is not used in any way.

explain plan for select * from t where flag = :f;
select * from table(dbms_xplan.display);

------------------------------------------------------------------------------
| Id  | Operation         | Name  | Rows  | Bytes   | Cost (%CPU) | Time     |
------------------------------------------------------------------------------
| 0   | SELECT STATEMENT  |       | 50000 | 488K    | 76 (2)      | 00:00:01 |
|* 1  | TABLE ACCESS FULL | T     | 50000 | 488K    | 76 (2)      | 00:00:01 |
------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------
1 - filter("FLAG"=:F)

In fact, when executing a query, Oracle "peeks" the values of the bind variables (this is called "bind peeking") and builds a plan based on these values. 
The real plan must be viewed directly in the cache when the request has already been sent for execution and parsed. For this, 
the dbms_xplan.display_cursor function is used; with the parameters specified in the example, 
it displays the plan of the last executed query and information about the bind variables: 
Now you can see that the optimizer took into account the value of the variable (the peeked binds section), 
adequately estimated the number of rows (135; the error does not affect the result) and chose access by index.

var f char(1)
exec :f := 'Y'
select * from t where flag = :f;
...
100 rows selected.

select * from table(dbms_xplan.display_cursor(format=>'typical +peeked_binds'));

SQL_ID 6pncxxhknwgqc, child number 0

-------------------------------------------------------------------------------------------
| Id  | Operation                   | Name    | Rows  | Bytes   | Cost (%CPU) | Time      |
-------------------------------------------------------------------------------------------
| 0   | SELECT STATEMENT            |         |       |         | 2 (100)     |           |
| 1   | TABLE ACCESS BY INDEX ROWID | T       | 135   |    1350 | 2 (0)       | 00:00:01  |
|* 2  | INDEX RANGE SCAN            | T_FLAG  | 135   |         | 1 (0)       | 00:00:01  |
-------------------------------------------------------------------------------------------

Peeked Binds (identified by position):
--------------------------------------
1 - :F (CHAR(30), CSID=873): 'Y'

Predicate Information (identified by operation id):
---------------------------------------------------
2 - filter("FLAG"=:F)

The problem is that the built "private" plan gets into the cache and will be reused for the same queries - without taking into account the values of the variables. 
This is not always a good thing: in our example, index access would be extremely inefficient for the value 'N'. 
Traditionally, the solution has been to use dynamic SQL with literals pasted into the query text - but the solution is unfortunate: 
in addition to the disadvantages discussed above, this approach is also dangerous due to the possibility of SQL injection. 
Therefore (since version 11g) Oracle is able to find and specially process queries that are sensitive to the values of the binding variables 
(this is called "adaptive cursor sharing"). When executing the query, 
the plan already in the cache is used, but the actual resources used are tracked and compared with the statistics of previous executions.

Let's look at some of the information from the library cache for our request: 
The request is marked as bind sensitive. Buffer_gets is the number of data blocks read. If it is found that the query performed worse with different values, 
then the next time it is executed, it will be marked as needing different plans (bind aware). 
Let's execute the same request with a different value of the flag field: Let's make sure that the request was executed with the plan from the cache, 
and at the same time we will demonstrate the possibility of displaying not only the expected, 
but also actual values in terms of plan (this is why the statistics_level parameter was first set):

select child_number, is_bind_sensitive, is_bind_aware, executions, buffer_gets from v$sql where sql_id='6pncxxhknwgqc';

CHILD_NUMBER IS_BIND_SENSITIVE IS_BIND_AWARE EXECUTIONS BUFFER_GETS
------------ ----------------- ------------- ---------- -----------
0             Y                 N             1         128

exec :f := 'N'
select * from t where flag = :f;
...
99900 rows selected.

select * from table(dbms_xplan.display_cursor(format=>'allstats last'));

SQL_ID 6pncxxhknwgqc, child number 0

---------------------------------------------------------------------------------------
| Id  | Operation                   | Name    | Starts  | E-Rows  | A-Rows  | Buffers |
---------------------------------------------------------------------------------------
| 0   | SELECT STATEMENT            |         | 1       |         | 99900   | 41368   |
| 1   | TABLE ACCESS BY INDEX ROWID | T       | 1       | 135     | 99900   | 41368   |
|* 2  | INDEX RANGE SCAN            | T_FLAG  | 1       | 135     | 99900   | 6842    |
---------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------
2 - access("FLAG"=:F)

There is a mismatch between the expected number of lines (135) and the real (99900). 
In addition, you can see that for execution it was necessary to read significantly more data than the first time (buffer_gets column): 
Let's execute the query again: Now the new plan is used, built for the new value of the bind variable (note the changed child number and the peeked section binds): 
This time the optimizer estimated the number of rows correctly (99856, with a small margin of error) and chose a full table scan. 
And there are now two versions of the plan for the same query in the library cache:

select child_number, is_bind_sensitive, is_bind_aware, executions, buffer_gets from v$sql where sql_id='6pncxxhknwgqc';

CHILD_NUMBER IS_BIND_SENSITIVE IS_BIND_AWARE EXECUTIONS BUFFER_GETS
------------ ----------------- ------------- ---------- -----------
0             Y                 N             2         41496

select * from t where flag = :f;
...
99900 rows selected.

select * from table(dbms_xplan.display_cursor(format=>'typical +peeked_binds'));

SQL_ID 6pncxxhknwgqc, child number 1

-----------------------------------------------------------------------------
| Id  | Operation         | Name  | Rows  | Bytes | Cost (%CPU) | Time      |
-----------------------------------------------------------------------------
| 0   | SELECT STATEMENT  |       |       |       | 77 (100)    |           |
|* 1  | TABLE ACCESS FULL | T     | 99856 | 975K  | 77 (3)      | 00:00:01  |
-----------------------------------------------------------------------------

Peeked Binds (identified by position):
--------------------------------------
1 - :F (CHAR(30), CSID=873): 'N'

Predicate Information (identified by operation id):
---------------------------------------------------
1 - filter("FLAG"=:F)

select child_number, is_bind_sensitive, is_bind_aware, executions, buffer_gets from v$sql where sql_id='6pncxxhknwgqc';

CHILD_NUMBER IS_BIND_SENSITIVE IS_BIND_AWARE EXECUTIONS BUFFER_GETS
------------ ----------------- ------------- ---------- -----------
0             Y                 N            2          41496
1             Y                 Y            1          6922



