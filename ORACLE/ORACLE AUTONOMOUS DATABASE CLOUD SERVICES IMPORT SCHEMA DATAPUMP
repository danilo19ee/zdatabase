++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+  ORACLE AUTONOMOUS DATABASE CLOUD SERVICES IMPORT SCHEMA DATAPUMP  +
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

#EXPORT SCHEMA CORE DATABASE (the version parameter is useful when the source is in a position in front of the target autonomous database)
expdp sh/sh@orcl \
	exclude=index, cluster, indextype, materialized_view, materialized_view_log \
	materialized_zonemap, db_link \ 
	data_options=group_partition_table_data \
	parallel=16 \
	schemas=sh \
	dumpfile=export%u.dmp \
	encryption_pwd_prompt=yes \
	directory=DATA_PUMP_DIR
	
#UPLOAD DUMP TO OBJECT STORAGE ORACLE
1 - In order to upload the .dmp file on object storage log in into your cloud console and click object storage:
2 - Select the compartment that you want to use and create a bucket
3 - Click on the bucket and click upload to upload the .dmp file.

#NOTE
At this point either you can use CLI (Command line Interface) or GUI (Graphic User interface) to upload the .dmp file. 
If your .dmp file is larger that 2Gib then you have to use CLI

4 - Select the .dmp file that you want to upload to object storage and then click upload object.

#CREATE AUTHENTICATION TOKEN
#NOTE
Authentication Token will help us access Object Storage from Autonomous DB. 

1 - Under Governance and Administration Section, Click on Identity tab and go to users
2 - Click on authorized user id and then click on Auth Token under resources on the left side to generate the Auth token.
3 - Click Generate Token, give it a description, and then click Generate token again and it will create the token for you. Remember to save the token. 
    Once the token is created and saved, you won't be able to retrieve it again.     
4 - You can click on the copy button and copy the token to a notepad. 


#CREATE CREDENTIAL AUTONOMOUS DATABASE (like directory)
BEGIN
	DBMS_CLOUD.CREATE_CREDENTIAL(
	credential_name => 'DEF_CRED_NAME',
	username => 'adwc_user@oracle.com',
	password => 'password' <-----------------------  (Use Authentication token Value here instead of the password)
	);
END;
/

#SET DEFAULT_CREDENTIAL AUTONOMOUS DATABASE 	
alter database property set default_credential='ADMIN.DEF_CRED_NAME';

#NOTE
In Oracle Data Pump version 18.3 and later, the credential argument authenticates Data Pump to the Cloud Object Storage service 
you are using for your source files. The dumpfile argument is a comma delimited list of URLs for your Data Pump files.
In Oracle Data Pump, if your source files reside on Oracle Cloud Infrastructure Object Storage you can use Oracle Cloud Infrastructure 
native URIs, Swift URIs, or pre-authenticated URIs. See DBMS_CLOUD Package File URI Formats for details on these file URI formats.
EXAMPLE : https://objectstorage.us-phoenix-1.oraclecloud.com/p/2xN-uDtWJNsiD910UCYGue/n/namespace-string/b/bucketname/o/channels.txt

#IMPORT DUMP TO AUTONOMOUS DATABASE 		
impdp admin/password@ADW_high \
	directory=data_pump_dir \
	credential=def_cred_name \
	dumpfile=https://swiftobjectstorage.us-phoenix-1.oraclecloud.com/v1/adwc/adwc_user/export%u,dump \
	parallel=16 \
	encryption_pwd_prompt=yes \
	partition_options=merge \
	transform=segment_attributes:n \
	transform=dwcs_cvt_iots:y transform=constraint_use_default_index:y \
	exclude=index, cluster, indextype, materialized_view \
	materialized_view_log, materialized_zonemap, db_link

#NOTE
For the best import performance use the HIGH database service for your import connection and set the PARALLEL parameter 
to the number of OCPUs in your Autonomous Data Warehouse

#LOAD LOG FILE TO OBJECT STORAGE ORACLE CLOUD
BEGIN
	DBMS_CLOUD.PUT_OBJECT(
	credential_name => 'DEF_CRED_NAME',
	object_uri => 'https://swiftobjectstorage.us-phoenix-1.oraclecloud.com/v1/adwc/adwc_user/import.log',
	directory_name => 'DATA_PUMP_DIR',
	file_name => 'import.log');
	END;
/
