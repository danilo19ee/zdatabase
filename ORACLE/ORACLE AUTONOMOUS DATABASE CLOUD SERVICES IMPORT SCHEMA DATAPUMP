++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+  ORACLE AUTONOMOUS DATABASE CLOUD SERVICES IMPORT SCHEMA DATAPUMP  +
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

#EXPORT SCHEMA CORE DATABASE (the version parameter is useful when the source is in a position in front of the target autonomous database)
expdp sh/sh@orcl \
	exclude=index, cluster, indextype, materialized_view, materialized_view_log \
	materialized_zonemap, db_link \ 
	data_options=group_partition_table_data \
	parallel=16 \
	schemas=sh \
	dumpfile=export%u.dmp \
	encryption_pwd_prompt=yes \
	directory=DATA_PUMP_DIR
	
#CREATE CREDENTIAL AUTONOMOUS DATABASE (like directory)
BEGIN
	DBMS_CLOUD.CREATE_CREDENTIAL(
	credential_name => 'DEF_CRED_NAME',
	username => 'adwc_user@oracle.com',
	password => 'password'
	);
END;
/

#SET DEFAULT_CREDENTIAL AUTONOMOUS DATABASE 	
alter database property set default_credential='ADMIN.DEF_CRED_NAME';

#NOTE
In Oracle Data Pump version 18.3 and later, the credential argument authenticates Data Pump to the Cloud Object Storage service 
you are using for your source files. The dumpfile argument is a comma delimited list of URLs for your Data Pump files.
In Oracle Data Pump, if your source files reside on Oracle Cloud Infrastructure Object Storage you can use Oracle Cloud Infrastructure 
native URIs, Swift URIs, or pre-authenticated URIs. See DBMS_CLOUD Package File URI Formats for details on these file URI formats.
EXAMPLE : https://objectstorage.us-phoenix-1.oraclecloud.com/p/2xN-uDtWJNsiD910UCYGue/n/namespace-string/b/bucketname/o/channels.txt

#IMPORT DUMP TO AUTONOMOUS DATABASE 		
impdp admin/password@ADW_high \
	directory=data_pump_dir \
	credential=def_cred_name \
	dumpfile=https://swiftobjectstorage.us-phoenix-1.oraclecloud.com/v1/adwc/adwc_user/export%u,dump \
	parallel=16 \
	encryption_pwd_prompt=yes \
	partition_options=merge \
	transform=segment_attributes:n \
	transform=dwcs_cvt_iots:y transform=constraint_use_default_index:y \
	exclude=index, cluster, indextype, materialized_view \
	materialized_view_log, materialized_zonemap, db_link

#NOTE
For the best import performance use the HIGH database service for your import connection and set the PARALLEL parameter 
to the number of OCPUs in your Autonomous Data Warehouse

#LOAD LOG FILE TO OBJECT STORAGE ORACLE CLOUD
BEGIN
	DBMS_CLOUD.PUT_OBJECT(
	credential_name => 'DEF_CRED_NAME',
	object_uri => 'https://swiftobjectstorage.us-phoenix-1.oraclecloud.com/v1/adwc/adwc_user/import.log',
	directory_name => 'DATA_PUMP_DIR',
	file_name => 'import.log');
	END;
/
